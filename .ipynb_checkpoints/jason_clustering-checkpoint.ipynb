{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project - Team Isaiah Thomas \n",
    "## Kishan Rajasekhar and Jason Kandu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kisha\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "plt.style.use('ggplot')\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mltools as ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_train = np.loadtxt('X_train.txt')\n",
    "# Y_train = np.loadtxt('y_train.txt')\n",
    "# X_test = np.loadtxt('X_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import AdaBoostClassifier\n",
    "# from sklearn import metrics\n",
    "# ada_clf = AdaBoostClassifier()\n",
    "# ada_clf.fit(X_train, Y_train)\n",
    "# X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.1, random_state=42)\n",
    "# ada_predictions = ada_clf.predict_proba(X_val)\n",
    "# # B = np.reshape(ada_predictions, [-1, 2])\n",
    "# # print ada_predictions.shape\n",
    "# # print ada_predictions\n",
    "# np.savetxt('Yhat_adapredict.txt',np.vstack( (np.arange(len(ada_predictions)) , ada_predictions[:,1] )).T,'%d, %.2f',header='ID,Prob1',comments='',delimiter=',')\n",
    "# # np.savetxt('Yhat_adapredict.txt',np.vstack( (np.arange(len(ada_predictions)) , ada_predictions[:] )).T,'%d, %.2f',header='ID,Prob1',comments='',delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.metrics import roc_curve, auc\n",
    "# false_positive_rate, true_positive_rate, thresholds = roc_curve(Y_val, ada_predictions[:,1])\n",
    "# roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "# print roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "X_train.txt not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ec3fb9a0fe74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenfromtxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"X_train.txt\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenfromtxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Y_train.txt\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mXv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mYt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mYv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplitData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.80\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mXe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenfromtxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'X_test.txt'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\kisha\\Anaconda2\\lib\\site-packages\\numpy\\lib\\npyio.pyc\u001b[0m in \u001b[0;36mgenfromtxt\u001b[0;34m(fname, dtype, comments, delimiter, skip_header, skip_footer, converters, missing_values, filling_values, usecols, names, excludelist, deletechars, replace_space, autostrip, case_sensitive, defaultfmt, unpack, usemask, loose, invalid_raise, max_rows)\u001b[0m\n\u001b[1;32m   1508\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1510\u001b[0;31m                 \u001b[0mfhd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rbU'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1511\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1512\u001b[0m                 \u001b[0mfhd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\kisha\\Anaconda2\\lib\\site-packages\\numpy\\lib\\_datasource.pyc\u001b[0m in \u001b[0;36mopen\u001b[0;34m(path, mode, destpath)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0mds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdestpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m     \u001b[1;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\kisha\\Anaconda2\\lib\\site-packages\\numpy\\lib\\_datasource.pyc\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, path, mode)\u001b[0m\n\u001b[1;32m    499\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0m_file_openers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mext\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfound\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m             \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s not found.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: X_train.txt not found."
     ]
    }
   ],
   "source": [
    "X = np.genfromtxt(\"data/X_train.txt\",delimiter=' ')\n",
    "Y = np.genfromtxt(\"data/Y_train.txt\",delimiter=' ')\n",
    "Xt,Xv,Yt,Yv = ml.splitData(X,Y,0.80)\n",
    "\n",
    "Xe = np.genfromtxt('data/X_test.txt',delimiter=' ')\n",
    "\n",
    "def auc(soft,Y):\n",
    "    \"\"\"Manual AUC function for applying to soft prediction vectors\"\"\"\n",
    "    indices = np.argsort(soft)         # sort data by score value\n",
    "    Y = Y[indices]\n",
    "    sorted_soft = soft[indices]\n",
    "    \n",
    "    # compute rank (averaged for ties) of sorted data\n",
    "    dif = np.hstack( ([True],np.diff(sorted_soft)!=0,[True]) )\n",
    "    r1  = np.argwhere(dif).flatten()\n",
    "    r2  = r1[0:-1] + 0.5*(r1[1:]-r1[0:-1]) + 0.5\n",
    "    rnk = r2[np.cumsum(dif[:-1])-1]\n",
    "    \n",
    "    # number of true negatives and positives\n",
    "    n0,n1 = sum(Y == 0), sum(Y == 1)\n",
    "    \n",
    "    # compute AUC using Mann-Whitney U statistic\n",
    "    result = (np.sum(rnk[Y == 1]) - n1 * (n1 + 1.0) / 2.0) / n1 / n0\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "nClust = 15\n",
    "np.random.seed(0)\n",
    "Z,T,pZ,ll = ml.cluster.gmmEM(Xt[:10000,:],K=nClust,init='k++',max_iter=50)\n",
    "\n",
    "Cluster_GMM = ml.bayes.gaussClassify()\n",
    "# Manually copy the EM Gaussian components into the Gaussian Bayes Classifier:\n",
    "Cluster_GMM.classes = np.arange(nClust)\n",
    "Cluster_GMM.means = T['mu']\n",
    "Cluster_GMM.covars = [ T['sig'][:,:,i]+.05*np.eye(Xt.shape[1]) for i in range(nClust) ]\n",
    "Cluster_GMM.probs = T['pi']\n",
    "\n",
    "# Find cluster membership probabilities for each data set:\n",
    "XtC = Cluster_GMM.predictSoft(Xt)\n",
    "XvC = Cluster_GMM.predictSoft(Xv)\n",
    "XeC = Cluster_GMM.predictSoft(Xe)\n",
    "\n",
    "# Create extended feature set:  features X times membership probability for each cluster\n",
    "XtC2 = np.einsum('ij,ik->ijk',XtC,Xt).reshape((Xt.shape[0],Xt.shape[1]*nClust))\n",
    "XvC2 = np.einsum('ij,ik->ijk',XvC,Xv).reshape((Xv.shape[0],Xv.shape[1]*nClust))\n",
    "XeC2 = np.einsum('ij,ik->ijk',XeC,Xe).reshape((Xe.shape[0],Xe.shape[1]*nClust))\n",
    "\n",
    "# Regress (should really use a classifier...)\n",
    "linr2 = ml.linear.linearRegress(XtC2,Yt, reg=1e-3)\n",
    "Pv3 = linr2.predict(XvC2)[:,0]\n",
    "Pe3 = linr2.predict(XeC2)[:,0]\n",
    "\n",
    "#toKaggle('Pe3.csv',Pe3)\n",
    "print \"3: Clustered LinRegress: MSE ~\",linr2.mse(XvC2,Yv),'; AUC = ',auc(Pv3,Yv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
